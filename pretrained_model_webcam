#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Dec 11 18:08:27 2020

@author: nashe
"""

import numpy as np
import cv2 as cv

#webcam stream 
wb_video_stream = cv.VideoCapture(0)

while True:
    ret, frame = wb_video_stream.read()    
    
    #get the image height
    img_height = frame.shape[0]
    
    #get the image width
    img_width = frame.shape[1]
    
    #non-maxima suppresion confidence
    SUP_CONF = 0.5
    MS_THRESHOLD = 0.4
    
      
    img_blob = cv.dnn.blobFromImage(frame, 0.003922, (416,416), swapRB=True, crop=False)
    
    class_labels = ["person","bicycle","car","motorcycle","airplane","bus","train","truck","boat","traffic light","fire hydrant","stop sign","parking meter","bench","bird","cat","dog","horse","sheep","cow","elephant","bear","zebra","giraffe","backpack","umbrella","handbag","tie","suitcase","frisbee","skis","snowboard","sports ball","kite","baseball bat","baseball glove","skateboard","surfboard","tennis racket","bottle","wine glass","cup","fork","knife","spoon","bowl","banana","apple","sandwich","orange","broccoli","carrot","hot dog","pizza","donut","cake","chair","couch","potted plant","bed","dining table","toilet","tv","laptop","mouse","remote","keyboard","cell phone","microwave","oven","toaster","sink","refrigerator","book","clock","vase","scissors","teddy bear","hair drier","toothbrush"]
    
    '''Declare the list of colors as a generic python array
        Split based on ',' and for every split change the type to int
        convert that to a numpy array to apply color mask to the image numpy array
    '''
    class_colors = ["0,255,0", "0,0,255", "255,0,0", "0,255,255"]
    class_colors = [np.array(color.split(",")).astype("int") for color in class_colors]
    class_colors = np.array(class_colors)
    class_colors = np.tile(class_colors, (16, 1))
    
    '''load pretrained model,
    input pre processed blob into model and pass through the model
    obtain the detection predictions by the model using forward() method'''
    
    #convolutionary neural network
    
    model = cv.dnn.readNetFromDarknet('model/yolov3.cfg', 'model/yolov3.weights')
    
    #get all layers from the yolo network
    #loop and find the last layer (output layer) for the network
    layers = model.getLayerNames()
    output_layer = [layers[layer[0] - 1] for layer in model.getUnconnectedOutLayers()]
    
    #input pre processed blob into model and pass through the model
    model.setInput(img_blob)
    
    #obtain the detection layers by fowarding through till the output layer
    detection_layers = model.forward(output_layer)
    
    #non max supression
    class_ids_list = []
    boxes_list = []
    confidence_list = []
    
    #loop over each of the layer outputs
    for detection_layer in detection_layers:
        #loop over the detections
        for object_detection in detection_layer:
            #obj detections [ 1 to 4 ] => will have the two center points, box width and box height
            #obj_detections[5] =? will have scores for all the objects within the bounding box
            all_scores = object_detection[5:]
            predicted_class_id = np.argmax(all_scores)
            prediction_confidence = all_scores[predicted_class_id]
            
            #take only predictions with good confidence level
            if (prediction_confidence > 0.20):
                #get the predicted label
                predicted_class_label = class_labels[predicted_class_id]
                #obtain the bounding box co-ordinates for actual image from resized image size
                bounding_box = object_detection[0:4] * np.array([img_width, img_height, img_width, img_height])
                (box_center_x_pt, box_center_y_pt, box_width, box_height) = bounding_box.astype("int")
                
                start_x_pt = int(box_center_x_pt - (box_width / 2))
                start_y_pt = int(box_center_y_pt - (box_height / 2))
                
                
                class_ids_list.append(predicted_class_id)
                confidence_list.append(float(prediction_confidence))
                boxes_list.append([start_x_pt, start_y_pt, int(box_width), int(box_height)])
                          
                #get a random mask color from the numpy array of colors
                box_color = class_colors[predicted_class_id % 64]
                
                #convert the colro numpy array as a list and apply to text and box
                box_color = [int(c) for c in box_color]
                
                #print prediction in console
                predicted_class_label = "{} : {:.2f}%".format(predicted_class_label, prediction_confidence * 100)
                print("predicted object {}".format(predicted_class_label))
                
    #applying the NMW will return only the selected max value ids while suppressing the non maximym (weak) overlapping bounding boxes            
    max_value_ids = cv.dnn.NMSBoxes(boxes_list, confidence_list, SUP_CONF, MS_THRESHOLD )
                
    for max_val_id in max_value_ids:
        max_class_id = max_val_id[0]
        box = boxes_list[max_class_id]
        start_x_pt = box[0]
        start_y_pt = box[1]
        box_width = box[2]
        box_height = box[3]
        
        end_x_pt = start_x_pt + box_width
        end_y_pt = start_y_pt + box_height
        
        #get the predicted class id and label
        predicted_class_id = class_ids_list[max_class_id]
        predicted_class_label = class_labels[predicted_class_id]
        prediction_confidence = confidence_list[max_class_id]
    
        #print rectangle and text in the image
        cv.rectangle(frame, (start_x_pt, start_y_pt), (end_x_pt, end_y_pt), box_color,1)
        cv.putText(frame, predicted_class_label, (start_x_pt, start_y_pt - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, box_color)
        
        cv.imshow("Detection Output", frame)
    
    
    if cv.waitKey(1) & 0xFF == ord('q') :
        break

#release the stream from the camera and clsoe all open cv windows
wb_video_stream.release()
cv.destroyAllWindows         
